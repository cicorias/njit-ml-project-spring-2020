{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Defining a Classification Problem\n",
    "\n",
    "The following section explores some ideas of turning stock price predictions into a classification ML problem. Namely, we will explore two questions:\n",
    "\n",
    "1) Can we tell if a stock will go up or down tomorrow? (It turns out, this is quite difficult)\n",
    "\n",
    "2) Can we tell if a stock is \"trending up\" or \"trending down\"? (This shows a bit of optimism.\n",
    "\n",
    "Our approach is as follows:\n",
    "\n",
    "1a) If _perfectly_ executed (that is, if we had actual future data), how much money would this strategy make compared to just buying and holding a stock? We do some backtesting to get a benchmark for the efficacy of the approach.\n",
    "\n",
    "1b) How realistic is it to predict such movement? We discover that a less-lucrative approach (when executed \"perfectly\") might be better in practice due to our ability to actually predict it.\n",
    "\n",
    "2) Using 69 well established technical indicators for trend, momentum, volatility, and volume, can we predict the movement of a stock? How correlated are these indicators? How useful are all of these features in our prediction? We do a correlation analysis and a Random Forest model to assess.\n",
    "\n",
    "3) Could we do better (albeit, less clearly) by creating the same number of features as selected in step 2 as \"fake features\" by doing a PCA on the original 69 indicators? Can we improve the accuracy of our top features by adding an element of non-linearity using the Kernel trick?\n",
    "\n",
    "4) How can we account for the timeseries nature of stocks? We explore adding lag variables to our feature matrix. We also explored \"slopes\" using linear regression but they were not particularly helpful and have been dropped from the final presentation.\n",
    "\n",
    "5) Finally, we take a look at a non-linear approach -- the Multi-Layer Perceptron. With the inclusion of the lag variables and two hidden layers, we achieve promising results (>90%) for predicting our chosen indicator. This leaves us with a sense of optimism and motivation for further exploration. We would next investigate engineering more time-related features, as well as using a Recurrent Neural Networks which is well suited for time series data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Support Clases\n",
    "We utilize the following classes in these sections to help back test, create labels, and engineer features:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import ta\n",
    "\n",
    "\n",
    "class StockTechnicals:\n",
    "    \"\"\"\n",
    "    A class for creating technical indicators of stocks as features and labels from various strategies for training\n",
    "    Machine Learning models\n",
    "    :param data: A pandas dataframe of a daily stock ticker data\n",
    "    Usage:\n",
    "    a = StockTechnicals(data)\n",
    "    X = a.features\n",
    "    y = a.price_will_rise()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self._features = ta.add_all_ta_features(\n",
    "            self.data,\n",
    "            open=\"Open\",\n",
    "            high=\"High\",\n",
    "            low=\"Low\",\n",
    "            close=\"Close\",\n",
    "            volume=\"Volume\"\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def features(self):\n",
    "        return self._features.drop(\n",
    "            columns=[\n",
    "                \"Date\",\n",
    "                \"Open\",\n",
    "                \"High\",\n",
    "                \"Low\",\n",
    "                \"Close\",\n",
    "                \"Adj Close\",\n",
    "                \"Volume\",\n",
    "                'trend_psar_up',\n",
    "                'trend_psar_down',\n",
    "                'trend_psar']\n",
    "        ).dropna()\n",
    "\n",
    "    # Can add more derived metrics here\n",
    "    # e.g. slopes, cross-overs\n",
    "    def add_slopes(self, metrics=(), days=()):\n",
    "        if not metrics:\n",
    "            metrics = list(self.features)\n",
    "        for m in metrics:\n",
    "            for d in days:\n",
    "                self._features[f\"{m}_{d}_day_slope\"] = self._features.apply(self._add_slope, metric=m, days=d, axis=1)\n",
    "\n",
    "    def _add_slope(self, row, metric, days=3):\n",
    "        if row.name < days + 1:\n",
    "            return None\n",
    "        x = np.arange(days)\n",
    "        A = np.vstack([x, np.ones(len(x))]).T\n",
    "        y = self._features.loc[row.name - days:row.name - 1, metric].values\n",
    "        slope, _ = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "        return slope\n",
    "\n",
    "    def add_lags(self, metrics=(), days=()):\n",
    "        if not metrics:\n",
    "            metrics = list(self.features)\n",
    "        for m in metrics:\n",
    "            for d in days:\n",
    "                self._features[f\"{m}_{d}_day_lag\"] = self._features.apply(self._add_lag, metric=m, days=d, axis=1)\n",
    "\n",
    "    def _add_lag(self, row, metric, days=3):\n",
    "        if row.name < days + 1:\n",
    "            return None\n",
    "        return self._features.loc[row.name - days, metric]\n",
    "\n",
    "    # Possible Strategy labels\n",
    "\n",
    "    def price_will_rise(self, days=1):\n",
    "        return np.array(self.features.apply(self._price_will_rise, days=days, axis=1))\n",
    "\n",
    "    def _price_will_rise(self, row, days=1):\n",
    "        try:\n",
    "            if self.data.loc[row.name + days, 'Adj Close'] > self.data.loc[row.name, 'Adj Close']:\n",
    "                return 1\n",
    "            return 0\n",
    "        except KeyError:\n",
    "            return None\n",
    "\n",
    "    def future_sma_higher_than_current_price(self, days=7):\n",
    "        # This metric is the most promising as far as an investment strategy\n",
    "        return np.array(self.features.apply(self._future_sma_v_price, days=days, axis=1))\n",
    "\n",
    "    def _future_sma_v_price(self, row, days=7):\n",
    "        try:\n",
    "            future_sma = np.mean([self.data.loc[row.name + day + 1, 'Adj Close'] for day in range(days)])\n",
    "        except KeyError:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            if future_sma > self.data.loc[row.name, 'Adj Close']:\n",
    "                return 1\n",
    "            return 0\n",
    "        except KeyError:\n",
    "            return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyalgotrade import strategy\n",
    "\n",
    "\n",
    "class TradeHoldStrategy(strategy.BacktestingStrategy):\n",
    "    \"\"\"\n",
    "    A class to test strategies based on a feed of signals (1's and 0's)\n",
    "    The strategy buys on next 1 and holds until next 0, when it sells and repeats.\n",
    "    :param future_signals: numpy array of signals of the same length as the feed on which to trade\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feed, instrument, future_signals, verbose=False):\n",
    "        strategy.BacktestingStrategy.__init__(self, feed)\n",
    "        self.instrument = instrument\n",
    "        self.future_signals = future_signals\n",
    "        self.adj_close = feed[instrument].getAdjCloseDataSeries()\n",
    "        self.day = 0\n",
    "        self.position = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def onBars(self, bars):\n",
    "        try:\n",
    "            todays_signal = self.future_signals[self.day]\n",
    "            if self.day == 0:\n",
    "                yesterdays_signal = 0\n",
    "            else:\n",
    "                yesterdays_signal = self.future_signals[self.day - 1]\n",
    "\n",
    "            if todays_signal > yesterdays_signal:\n",
    "                self.position = self.enterLong(self.instrument, 100)\n",
    "            elif todays_signal < yesterdays_signal:\n",
    "                self.position.exitMarket()\n",
    "        except IndexError:\n",
    "            pass\n",
    "        self.day += 1\n",
    "\n",
    "    def onEnterOk(self, position):\n",
    "        if self.verbose:\n",
    "            exec_info = position.getEntryOrder().getExecutionInfo()\n",
    "            self.info(\"BUY at $%.2f\" % (exec_info.getPrice()))\n",
    "\n",
    "    def onExitOk(self, position):\n",
    "        if self.verbose:\n",
    "            exec_info = position.getExitOrder().getExecutionInfo()\n",
    "            self.info(\"SELL at $%.2f\" % (exec_info.getPrice()))\n",
    "        self.position = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Picking a Strategy as a Classificaion Problem"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The following code backtests some possible \"returns\" when implementing a strategy using the \n",
    "# actual future data to generate signals. We use the convention TradeHoldStrategy where we are \n",
    "# attempting to find a signal (a classification) to tell us to buy, hold or sell.\n",
    "# It is our goal to find one that proves to make money and that we can somewhat accurately predict.\n",
    "\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.features.build_features import StockTechnicals\n",
    "\n",
    "from src.models.backtest_strategy import TradeHoldStrategy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load data using MSFT \n",
    "ticker = \"MSFT\"\n",
    "all_daily_data = pd.read_csv(f'../data/{ticker}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a feature matrix and some labels using our handy StockTechnicals class\n",
    "# we will actually only need labels for this decision, as we're using observed data\n",
    "technicals = StockTechnicals(all_daily_data)\n",
    "X = technicals.features\n",
    "y = technicals.price_will_rise()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### BACKTESTING ###\n",
    "# import a backtesting library\n",
    "from pyalgotrade.barfeed import yahoofeed\n",
    "from pyalgotrade.stratanalyzer import returns, trades"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# build our backtesing feed using MSFT daily data\n",
    "base_feed = yahoofeed.Feed()\n",
    "base_feed.addBarsFromCSV(f\"{ticker}\", f'../data/{ticker}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# As a benchmark, we will buy 100 shares of MSFT on day one and hold. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# buy one share on day one and hold as a benchmark\n",
    "benchmark_feed = deepcopy(base_feed)\n",
    "benchmark_trades = np.ones(len(all_daily_data))\n",
    "benchmark_strat = TradeHoldStrategy(benchmark_feed, f'{ticker}', benchmark_trades)\n",
    "\n",
    "# performance metrics for strategy evaluation\n",
    "ret_analyzer = returns.Returns()\n",
    "benchmark_strat.attachAnalyzer(ret_analyzer)\n",
    "tradesAnalyzer = trades.Trades()\n",
    "benchmark_strat.attachAnalyzer(tradesAnalyzer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# backtest the strategy \n",
    "benchmark_strat.run()\n",
    "bmk_value = round(benchmark_strat.getResult() - 1000000, 2)\n",
    "print(f\"Final portfolio increase: ${bmk_value}\")\n",
    "print(f\"Total trades: {tradesAnalyzer.getCount()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now let's backtest a strategy with the training labels we created in StockTechnicals. The \n",
    "# strategy is to BUY 100 shares if we predict the price will rise the following day and HOLD \n",
    "# until we predict the market will go down the following day, when we SELL 100 shares and \n",
    "# wait until we predict another rise.\n",
    "# Note that there is some loss as we can't trade after-hours in our sim and open prices do not \n",
    "# always match closing prices, but it is still very good (results below)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "perf_feed = deepcopy(base_feed)\n",
    "perf_trades = np.concatenate([np.zeros(len(all_daily_data) - len(y)), y])\n",
    "perf_strat = TradeHoldStrategy(perf_feed, f'{ticker}', perf_trades)\n",
    "\n",
    "# performance metrics\n",
    "ret_analyzer = returns.Returns()\n",
    "perf_strat.attachAnalyzer(ret_analyzer)\n",
    "tradesAnalyzer = trades.Trades()\n",
    "perf_strat.attachAnalyzer(tradesAnalyzer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# backtest the strategy\n",
    "perf_strat.run()\n",
    "perf_strat_value = round(perf_strat.getResult() - 1000000, 2)\n",
    "print(f\"Final portfolio increase: ${perf_strat_value}\")\n",
    "perf_pct_improve = round((perf_strat_value / bmk_value - 1) * 100, 1)\n",
    "print(f\"Percentage gain v. buy-and-hold bmk: {perf_pct_improve}%\")\n",
    "print(\"Total trades: %d\" % (tradesAnalyzer.getCount()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# As we can see, perfect execution of this strategy would improve our returns by over 400%\n",
    "# However daily stock movement is notoriously difficult to predict, so we'll explore another\n",
    "# strategy as well."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Backtest another strategy. This strategy is to to BUY 100 shares if we predict the N-day SMA \n",
    "# will be higher than the current stock price in N days, and HOLD until we predict the N-day SMA \n",
    "# will be lower than the current stock price in N days, when we SELL 100 shares and wait until \n",
    "# we predict another rise.\n",
    "N = 26\n",
    "\n",
    "# generate our labels using our StockTechnicals class\n",
    "y_sma = technicals.future_sma_higher_than_current_price(days=N)\n",
    "\n",
    "sma_feed = deepcopy(base_feed)\n",
    "sma_trades = np.concatenate([np.zeros(len(all_daily_data) - len(y_sma)), y_sma])\n",
    "sma_strat = TradeHoldStrategy(sma_feed, f'{ticker}', sma_trades)\n",
    "\n",
    "# performance metrics\n",
    "ret_analyzer = returns.Returns()\n",
    "sma_strat.attachAnalyzer(ret_analyzer)\n",
    "tradesAnalyzer = trades.Trades()\n",
    "sma_strat.attachAnalyzer(tradesAnalyzer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run the N-day sma strategy\n",
    "sma_strat.run()\n",
    "sma_value = round(sma_strat.getResult() - 1000000, 2)\n",
    "print(f\"Final portfolio increase: ${sma_value}\")\n",
    "sma_pct_improve = round((sma_value / bmk_value - 1) * 100, 1)\n",
    "print(f\"Percentage gain v. buy-and-hold bmk: {sma_pct_improve}%\")\n",
    "print(\"Total trades: %d\" % (tradesAnalyzer.getCount()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# As we can see with this strategy, the potential returns are not as high, but \n",
    "# it's more conservative and likely a bit easier to predict as it's using a more general metrics\n",
    "# in the moving average rather than daily close data. We will demonstrate this next."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### EYEBALLING FOR FEASIBILITY ###\n",
    "# Using a naive, unoptimized Logistic Regression model, we will evaluate benchmark peformances for \n",
    "# each of the two strategies outlined above."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST NEXT DAY STRATEGY IN LOGISTIC REGRESSION\n",
    "\n",
    "# set up X_daily and y_daily (y has trailing nan values, so we truncate here) \n",
    "y_daily = y[~np.isnan(y)]\n",
    "X_daily = X[:len(y_daily)]\n",
    "\n",
    "# preprocess the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_daily, y_daily, random_state=2, stratify=y_daily)\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "# run a logistic regression\n",
    "for c in [0.01, 0.1, 1.0, 10, 100]:\n",
    "    lr = LogisticRegression(C=c, random_state=2, solver='liblinear')\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    y_pred = lr.predict(X_test_std)\n",
    "\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# As we can see above, a naive LogisticRegression doesn't do any better than simply guessing\n",
    "# whether the stock will rise the following day"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST N-DAY SMA STRATEGY IN LOGISTIC REGRESSION\n",
    "\n",
    "y_sma = y_sma[~np.isnan(y_sma)]\n",
    "X_sma = X[:len(y_sma)]\n",
    "\n",
    "# preprocess the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sma, y_sma, random_state=2, stratify=y_sma)\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "# run a logistic regression\n",
    "for c in [0.01, 0.1, 1.0, 10, 100]:\n",
    "    lr = LogisticRegression(C=c, random_state=2, solver='liblinear')\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    y_pred = lr.predict(X_test_std)\n",
    "\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compared to predicting the one-day return, predicting the 26-day sma rise is much more\n",
    "# promising. Our _very_ naive Logistic Regression classifer scores at almost 64%. For this\n",
    "# reason, we will move forward attempting to predict these labels."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Selection using Correlations and Random Forests"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.features.build_features import StockTechnicals\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load data using MSFT \n",
    "ticker = \"MSFT\"\n",
    "all_daily_data = pd.read_csv(f'../data/{ticker}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set up our X and y\n",
    "\n",
    "N = 26\n",
    "\n",
    "# create a feature matrix and some labels using our handy StockTechnicals class\n",
    "technicals = StockTechnicals(all_daily_data)\n",
    "X = technicals.features\n",
    "y = technicals.future_sma_higher_than_current_price(N)\n",
    "\n",
    "# we don't have the last N days of data\n",
    "y = y[~np.isnan(y)]\n",
    "X = X[:len(y)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2, stratify=y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# take a look at the relative importances of all features using a random forest \n",
    "feat_labels = list(X.columns)\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(f\"{f + 1:2}) {X.columns[indices[f]]:<28} {round(importances[indices[f]], 4):>}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check the top 20 features to see if any are correlated\n",
    "top_feats_X = X_train.iloc[:,indices[:20]]\n",
    "corr = top_feats_X.corr()\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(corr, annot = True, label = ticker)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# there are lots of correlated features, so let's remove them in order of priority\n",
    "ind_feats = []\n",
    "for i in indices:\n",
    "    # iterating in importance order, don't include a feature if it has a correlation\n",
    "    # stronger than 0.9 (or -0.9) with a features already included\n",
    "    if all(abs(X_train.corr().iloc[ind_feats, i]) < 0.9):\n",
    "        ind_feats.append(i)\n",
    "\n",
    "print(f'We are left with {len(ind_feats)} \"independent\" (non-correlated) features')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# observe feature importances of this subset using a new random forest\n",
    "ind_feats_X = X_train.iloc[:, ind_feats]\n",
    "\n",
    "ind_feats_forest = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "ind_feats_forest.fit(ind_feats_X, y_train)\n",
    "ind_importances = ind_feats_forest.feature_importances_\n",
    "\n",
    "for rk, (idx, imp) in enumerate(sorted(zip(ind_feats, ind_importances), key=lambda x: x[1], reverse=True)):\n",
    "    print(f\"{rk + 1:2}) {X.columns[idx]:<28} {round(imp, 4):>}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setting a threshold of 0.3 leaves us with 13 indicators as featres, which \n",
    "# sounds like a good place to start"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Take a look again at the correlation matrix of our top 13 features to make sure nothing changed\n",
    "top_feats_X = X_train.iloc[:,ind_feats[:13]]\n",
    "corr = top_feats_X.corr()\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(corr, annot = True, label = ticker)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exploring PCA and KPCA approaches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import KernelPCA, PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from src.features.build_features import StockTechnicals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load training data using MSFT\n",
    "train_ticker = \"MSFT\"\n",
    "all_msft_data = pd.read_csv(f'../data/{train_ticker}.csv')\n",
    "\n",
    "# number of future days for SMA to rise\n",
    "N = 26"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "technicals = StockTechnicals(all_msft_data)\n",
    "X = technicals.features\n",
    "y = technicals.future_sma_higher_than_current_price(N)\n",
    "\n",
    "# we don't have the last N days of data (they're in the future)\n",
    "y = y[~np.isnan(y)]\n",
    "X = X[:len(y)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# limit to top features as determined by a RandomForest in feature-selection.ipnyb\n",
    "top_features = [\n",
    "    'trend_visual_ichimoku_b',\n",
    "    'volume_obv',\n",
    "    'volatility_kcw',\n",
    "    'volatility_atr',\n",
    "    'trend_mass_index',\n",
    "    'trend_kst_sig',\n",
    "    'volume_cmf',\n",
    "    'trend_adx',\n",
    "    'trend_macd_signal',\n",
    "    'volatility_bbw',\n",
    "    'trend_kst_diff',\n",
    "    'momentum_tsi',\n",
    "    'trend_macd_diff',\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# limit X to top features only\n",
    "X_top = X[top_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top, y, random_state=2, stratify=y)\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run a logistic regression to get a benchmark performance on the top 13 features\n",
    "for c in [0.01, 0.1, 1.0, 10, 100]:\n",
    "    lr = LogisticRegression(C=c, random_state=2, solver='liblinear')\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    y_pred = lr.predict(X_test_std)\n",
    "\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\\n\"\n",
    "          f\"F1-Score:       {f1_score(y_test, y_pred)}\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Limiting to the top 13 features achieves an accuracy very close to using all 69 (~65% v ~69%).\n",
    "# As an alternative, let's see what happens when reducing to 13 \"fake\" features using PCA "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set up test and train datasets using full X\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2, stratify=y)\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "# fit a pca with 13 \"fake\" attributes\n",
    "pca = PCA(13, random_state=1, tol=0.1)\n",
    "X_train_std_pca = pca.fit_transform(X_train_std)\n",
    "X_test_std_pca = pca.transform(X_test_std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run a logistic regression with the 13-feature pca dataset\n",
    "for c in [0.01, 0.1, 1.0, 10, 100]:\n",
    "    lr = LogisticRegression(C=c, random_state=2, solver='liblinear')\n",
    "    lr.fit(X_train_std_pca, y_train)\n",
    "    y_pred = lr.predict(X_test_std_pca)\n",
    "\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\\n\"\n",
    "          f\"F1-Score:       {f1_score(y_test, y_pred)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Using a PCA with 13 \"fake\" attributes doesn't achieve better results than simply using\n",
    "# our 13 top attributes as selected from the RandomForest. Therefore, we'll stick with those\n",
    "# as they're more easily explained. Next we'll try using the kernel trick to see if we can\n",
    "# improve classification by temporarily projecting data into a higher dimensional space"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# trying out kpca\n",
    "\n",
    "for k in ('poly', 'rbf', 'sigmoid', 'cosine', 'precomputed'):\n",
    "    print(f\"\\nKernel: {k}\")\n",
    "    kpca = KernelPCA(n_components=13, random_state=1, kernel='poly', gamma=1.0)\n",
    "    X_train_std_kpca = kpca.fit_transform(X_train_std)\n",
    "    X_test_std_kpca = kpca.transform(X_test_std)\n",
    "    \n",
    "    # run a logistic regression\n",
    "    for c in [0.01, 0.1, 1.0, 10, 100]:\n",
    "        lr = LogisticRegression(C=c, random_state=2, solver='liblinear')\n",
    "        lr.fit(X_train_std_kpca, y_train)\n",
    "        y_pred = lr.predict(X_test_std_kpca)\n",
    "    \n",
    "        print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\\n\"\n",
    "              f\"F1-Score:       {f1_score(y_test, y_pred)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# It doesn't seem like the kernel trick with KPCA is very effective at improving our accuracy either.\n",
    "# Above is just a sample of the various hyperparameter combinations we attempted. It is our belief\n",
    "# that we will need to engineer additional features or implement deeper neural networks to improve \n",
    "# our classification accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adding Lag Variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Stocks are inherently a time-series prediction, so let's see if adding lag values to  various\n",
    "# metrics helps improve the prediction accuracy using a linear model at all\n",
    "\n",
    "lag_days = [1, 2, 3, 4, 5, 10, 20]\n",
    "\n",
    "# add lags is a convenience function I wrote to add trailing values to a list of metrics\n",
    "all_msft_data = pd.read_csv(f'../data/{train_ticker}.csv')\n",
    "technicals = StockTechnicals(all_msft_data)\n",
    "technicals.add_lags(metrics=top_features, days=lag_days)\n",
    "X = technicals.features\n",
    "y = technicals.future_sma_higher_than_current_price(26)\n",
    "\n",
    "# drop final 26 days which we don't have a y value\n",
    "y = y[~np.isnan(y)]\n",
    "X = X[:len(y)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# limit to top features as determined by a RandomForest in feature-selection.ipnyb\n",
    "top_features = [\n",
    "    'trend_visual_ichimoku_b',\n",
    "    'volume_obv',\n",
    "    'volatility_kcw',\n",
    "    'volatility_atr',\n",
    "    'trend_mass_index',\n",
    "    'trend_kst_sig',\n",
    "    'volume_cmf',\n",
    "    'trend_adx',\n",
    "    'trend_macd_signal',\n",
    "    'volatility_bbw',\n",
    "    'trend_kst_diff',\n",
    "    'momentum_tsi',\n",
    "    'trend_macd_diff',\n",
    "]\n",
    "\n",
    "top_features.extend([f\"{feat}_{n}_day_lag\" for feat in top_features for n in lag_days])\n",
    "X_top = X[top_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top, y, random_state=2, stratify=y)\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "# run a logistic regression\n",
    "for c in [0.01, 0.1, 1.0, 10, 100]:\n",
    "    lr = LogisticRegression(C=c, random_state=2, solver='liblinear')\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    y_pred = lr.predict(X_test_std)\n",
    "\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Even with lag variables it seems the data just aren't linearly separable.\n",
    "# Let's try a non-linear classifier like a multi-layer perceptron\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training a Multi-Layer Perceptron"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "for a in [0.001, 0.01, 0.1]:\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(39, 39), \n",
    "        solver='lbfgs', \n",
    "        max_iter=5000, \n",
    "        random_state=2, \n",
    "        alpha=a, \n",
    "        activation='relu')\n",
    "    mlp.fit(X_train_std, y_train)\n",
    "    y_pred = mlp.predict(X_test_std)\n",
    "\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# There are some early signs of optimism using the MLP classifier with\n",
    "# predictions as high as 93.6% accuracy with an alpha of 0.01. 39 units\n",
    "# two hidden layers was selected somewhat arbitrarily as 3x13 (# of impt features)\n",
    "# Other combinations - larger and smaller - were only nominally different and\n",
    "# often worse, so this is merely to demonstrate a more \"successful\" case. \n",
    "# Let's try some other hyperparameter combinations for fun."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for solver in ['adam', 'sgd']:\n",
    "    for activation in ['relu', 'tanh', 'logistic']:\n",
    "        mlp = MLPClassifier(\n",
    "            hidden_layer_sizes=(39, 39), \n",
    "            solver=solver,  \n",
    "            max_iter=1000, \n",
    "            random_state=2, \n",
    "            alpha=0.01, \n",
    "            activation=activation,\n",
    "            learning_rate='adaptive')\n",
    "        mlp.fit(X_train_std, y_train)\n",
    "        y_pred = mlp.predict(X_test_std)\n",
    "\n",
    "        print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\")\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Nothing in the above supercedes our initial MLP (this was an intentional demonstration)\n",
    "# Perhaps there's a chance we can predict the general \"trend\" of a stock somewhat accurately \n",
    "# with an MLP classifier on a handful of technical indicators along with some lag values.\n",
    "# Future analysis will be performed on engineering new features as well as recurrent nueral\n",
    "# network implementations, which are particularly well suited for timeseries data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}