{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The following code backtests some possible \"returns\" when implementing a strategy using the \n",
    "# actual future data to generate signals. We use the convention CrystalBallStrategy to remind \n",
    "# us that these strategies are only possible if we had a crystal ball to tell the future. It \n",
    "# is our goal to find one that proves to make money and that we can somewhat accurately predict.\n",
    "\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.features.build_features import StockTechnicals\n",
    "\n",
    "from src.models.backtest_strategy import TradeHoldStrategy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load data using MSFT \n",
    "ticker = \"MSFT\"\n",
    "all_daily_data = pd.read_csv(f'../data/{ticker}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a feature matrix and some labels using our handy StockTechnicals class\n",
    "# we will actually only need labels for this decision, as we're using observed data\n",
    "technicals = StockTechnicals(all_daily_data)\n",
    "X = technicals.features\n",
    "y = technicals.price_will_rise()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### BACKTESTING ###\n",
    "# import a backtesting library\n",
    "from pyalgotrade.barfeed import yahoofeed\n",
    "from pyalgotrade.stratanalyzer import returns, trades"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# build our backtesing feed using MSFT daily data\n",
    "base_feed = yahoofeed.Feed()\n",
    "base_feed.addBarsFromCSV(f\"{ticker}\", f'../data/{ticker}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# As a benchmark, we will buy 100 shares of MSFT on day one and hold. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# buy one share on day one and hold as a benchmark\n",
    "benchmark_feed = deepcopy(base_feed)\n",
    "benchmark_trades = np.ones(len(all_daily_data))\n",
    "benchmark_strat = TradeHoldStrategy(benchmark_feed, f'{ticker}', benchmark_trades)\n",
    "\n",
    "# performance metrics for strategy evaluation\n",
    "ret_analyzer = returns.Returns()\n",
    "benchmark_strat.attachAnalyzer(ret_analyzer)\n",
    "tradesAnalyzer = trades.Trades()\n",
    "benchmark_strat.attachAnalyzer(tradesAnalyzer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# backtest the strategy \n",
    "benchmark_strat.run()\n",
    "bmk_value = round(benchmark_strat.getResult() - 1000000, 2)\n",
    "print(f\"Final portfolio increase: ${bmk_value}\")\n",
    "print(f\"Total trades: {tradesAnalyzer.getCount()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now let's backtest a strategy with the training labels we created in StockTechnicals. The \n",
    "# strategy is to BUY 100 shares if we predict the price will rise the following day and HOLD \n",
    "# until we predict the market will go down the following day, when we SELL 100 shares and \n",
    "# wait until we predict another rise.\n",
    "# Note that there is some loss as we can't trade after-hours in our sim and open prices do not \n",
    "# always match closing prices, but it is still very good (results below)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "perf_feed = deepcopy(base_feed)\n",
    "perf_trades = np.concatenate([np.zeros(len(all_daily_data) - len(y)), y])\n",
    "perf_strat = TradeHoldStrategy(perf_feed, f'{ticker}', perf_trades)\n",
    "\n",
    "# performance metrics\n",
    "ret_analyzer = returns.Returns()\n",
    "perf_strat.attachAnalyzer(ret_analyzer)\n",
    "tradesAnalyzer = trades.Trades()\n",
    "perf_strat.attachAnalyzer(tradesAnalyzer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# backtest the strategy\n",
    "perf_strat.run()\n",
    "perf_strat_value = round(perf_strat.getResult() - 1000000, 2)\n",
    "print(f\"Final portfolio increase: ${perf_strat_value}\")\n",
    "perf_pct_improve = round((perf_strat_value / bmk_value - 1) * 100, 1)\n",
    "print(f\"Percentage gain v. buy-and-hold bmk: {perf_pct_improve}%\")\n",
    "print(\"Total trades: %d\" % (tradesAnalyzer.getCount()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# As we can see, perfect execution of this strategy would improve our returns by over 400%\n",
    "# However daily stock movement is notoriously difficult to predict, so we'll explore another\n",
    "# strategy as well."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Backtest another strategy. This strategy is to to BUY 100 shares if we predict the N-day SMA \n",
    "# will be higher than the current stock price in N days, and HOLD until we predict the N-day SMA \n",
    "# will be lower than the current stock price in N days, when we SELL 100 shares and wait until \n",
    "# we predict another rise.\n",
    "N = 26\n",
    "\n",
    "# generate our labels using our StockTechnicals class\n",
    "y_sma = technicals.future_sma_higher_than_current_price(days=N)\n",
    "\n",
    "sma_feed = deepcopy(base_feed)\n",
    "sma_trades = np.concatenate([np.zeros(len(all_daily_data) - len(y_sma)), y_sma])\n",
    "sma_strat = TradeHoldStrategy(sma_feed, f'{ticker}', sma_trades)\n",
    "\n",
    "# performance metrics\n",
    "ret_analyzer = returns.Returns()\n",
    "sma_strat.attachAnalyzer(ret_analyzer)\n",
    "tradesAnalyzer = trades.Trades()\n",
    "sma_strat.attachAnalyzer(tradesAnalyzer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run the N-day sma strategy\n",
    "sma_strat.run()\n",
    "sma_value = round(sma_strat.getResult() - 1000000, 2)\n",
    "print(f\"Final portfolio increase: ${sma_value}\")\n",
    "sma_pct_improve = round((sma_value / bmk_value - 1) * 100, 1)\n",
    "print(f\"Percentage gain v. buy-and-hold bmk: {sma_pct_improve}%\")\n",
    "print(\"Total trades: %d\" % (tradesAnalyzer.getCount()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# As we can see with this strategy, the potential returns are not as high, but \n",
    "# it's more conservative and likely a bit easier to predict as it's using a more general metrics\n",
    "# in the moving average rather than daily close data. We will demonstrate this next."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### EYEBALLING FOR FEASIBILITY ###\n",
    "# Using a naive, unoptimized Logistic Regression model, we will evaluate benchmark peformances for \n",
    "# each of the two strategies outlined above."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST NEXT DAY STRATEGY IN LOGISTIC REGRESSION\n",
    "\n",
    "# set up X_daily and y_daily (y has trailing nan values, so we truncate here) \n",
    "y_daily = y[~np.isnan(y)]\n",
    "X_daily = X[:len(y_daily)]\n",
    "\n",
    "# preprocess the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_daily, y_daily, random_state=2, stratify=y_daily)\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "# run a logistic regression\n",
    "for c in [0.01, 0.1, 1.0, 10, 100]:\n",
    "    lr = LogisticRegression(C=c, random_state=2, solver='liblinear')\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    y_pred = lr.predict(X_test_std)\n",
    "\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# As we can see above, a naive LogisticRegression doesn't do any better than simply guessing\n",
    "# whether the stock will rise the following day"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST N-DAY SMA STRATEGY IN LOGISTIC REGRESSION\n",
    "\n",
    "y_sma = y_sma[~np.isnan(y_sma)]\n",
    "X_sma = X[:len(y_sma)]\n",
    "\n",
    "# preprocess the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sma, y_sma, random_state=2, stratify=y_sma)\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "# run a logistic regression\n",
    "for c in [0.01, 0.1, 1.0, 10, 100]:\n",
    "    lr = LogisticRegression(C=c, random_state=2, solver='liblinear')\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    y_pred = lr.predict(X_test_std)\n",
    "\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compared to predicting the one-day return, predicting the 26-day sma rise is much more\n",
    "# promising. Our _very_ naive Logistic Regression classifer scores at almost 64%. For this\n",
    "# reason, we will move forward attempting to predict these labels."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DELETE ME\n",
    "# JUST A DEMO\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "for a in [0.1, 1.0, 10, 100]:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(7, 3), solver='lbfgs', random_state=2, alpha=a, activation='tanh')\n",
    "    mlp.fit(X_train_std, y_train)\n",
    "    y_pred = mlp.predict(X_test_std)\n",
    "\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.features.build_features import StockTechnicals\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load data using MSFT \n",
    "ticker = \"MSFT\"\n",
    "all_daily_data = pd.read_csv(f'../data/{ticker}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set up our X and y\n",
    "\n",
    "N = 26\n",
    "\n",
    "# create a feature matrix and some labels using our handy StockTechnicals class\n",
    "technicals = StockTechnicals(all_daily_data)\n",
    "X = technicals.features\n",
    "y = technicals.future_sma_higher_than_current_price(N)\n",
    "\n",
    "# we don't have the last N days of data\n",
    "y = y[~np.isnan(y)]\n",
    "X = X[:len(y)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2, stratify=y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# take a look at the relative importances of all features using a random forest \n",
    "feat_labels = list(X.columns)\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(f\"{f + 1:2}) {X.columns[indices[f]]:<28} {round(importances[indices[f]], 4):>}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check the top 20 features to see if any are correlated\n",
    "top_feats_X = X_train.iloc[:,indices[:20]]\n",
    "corr = top_feats_X.corr()\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(corr, annot = True, label = ticker)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# there are lots of correlated features, so let's remove them in order of priority\n",
    "ind_feats = []\n",
    "for i in indices:\n",
    "    # iterating in importance order, don't include a feature if it has a correlation\n",
    "    # stronger than 0.9 (or -0.9) with a features already included\n",
    "    if all(abs(X_train.corr().iloc[ind_feats, i]) < 0.9):\n",
    "        ind_feats.append(i)\n",
    "\n",
    "print(f'We are left with {len(ind_feats)} \"independent\" (non-correlated) features')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# observe feature importances of this subset using a new random forest\n",
    "ind_feats_X = X_train.iloc[:, ind_feats]\n",
    "\n",
    "ind_feats_forest = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "ind_feats_forest.fit(ind_feats_X, y_train)\n",
    "ind_importances = ind_feats_forest.feature_importances_\n",
    "\n",
    "for rk, (idx, imp) in enumerate(sorted(zip(ind_feats, ind_importances), key=lambda x: x[1], reverse=True)):\n",
    "    print(f\"{rk + 1:2}) {X.columns[idx]:<28} {round(imp, 4):>}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setting a threshold of 0.3 leaves us with 13 indicators as featres, which \n",
    "# sounds like a good place to start"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Take a look again at the correlation matrix of our top 13 features to make sure nothing changed\n",
    "top_feats_X = X_train.iloc[:,ind_feats[:13]]\n",
    "corr = top_feats_X.corr()\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(corr, annot = True, label = ticker)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}