{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notebook setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook functions and setup\n",
    "The following are functions that are used within the notebook to reduce and DRY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "#eventually mode all but essential local to function blocks.\n",
    "#import datetime\n",
    "import logging\n",
    "#import math\n",
    "import os\n",
    "import sys\n",
    "#from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import requests\n",
    "import seaborn as sns\n",
    "import ta\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import (explained_variance_score, mean_squared_error,\n",
    "                             r2_score)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from ta import add_all_ta_features\n",
    "\n",
    "from src.features.build_features import StockTechnicals\n",
    "from src.models.backtest_strategy import TradeHoldStrategy\n",
    "from src.visualization.visualize import DisplayTicker\n",
    "\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, \n",
    "    level=logging.INFO) #DEBUG to see all.\n",
    "\n",
    "logger = logging.getLogger('NOTEBOOK_LOGGER')\n",
    "\n",
    "\n",
    "# functions...\n",
    "\n",
    "## pulling data.\n",
    "def pull_data_files(data_path, symbols, start, end):\n",
    "    import os\n",
    "    import requests\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    parms = { 'period1': start, 'period2':end, 'interval': '1d', 'events': 'history' }\n",
    "    base_url = 'https://query1.finance.yahoo.com/v7/finance/download/{}'\n",
    "    for s in symbols:\n",
    "        r = requests.get(base_url.format(s), params=parms)\n",
    "        logger.debug('calling: {}'.format(r.url))\n",
    "\n",
    "        filename = '{}/{}.csv'.format(data_path, s).replace('^', '_')\n",
    "\n",
    "        with open(filename, 'wb') as fd:\n",
    "            for chunk in r.iter_content(chunk_size=128):\n",
    "                fd.write(chunk)\n",
    "\n",
    "\n",
    "    logger.info('files downloaded to {}'.format(data_path))\n",
    "\n",
    "\n",
    "def get_epoch_date(y,m,d):\n",
    "    import datetime\n",
    "    import math\n",
    "    return math.trunc(datetime.datetime(y,m,d).timestamp())\n",
    "\n",
    "\n",
    "def convert_data_add_features(stock_ticker_csv, start_date, end_date, close_feature='Close'):\n",
    "    \"\"\"\n",
    "    stock_ticker_csv : csv file\n",
    "    end_date : string\n",
    "    days_to_backtrack : int\n",
    "    Takes in a CSV File and converts the date to numbers\n",
    "    Returns DF with Dates converted to numerical format and the original Dates for plotting\n",
    "    Adds some features to the DataFrame\n",
    "    \"\"\"\n",
    "    from datetime import datetime, timedelta\n",
    "    start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    " \n",
    "\n",
    "    # Load the CSV File\n",
    "    stock_ticker = pd.read_csv(stock_ticker_csv, index_col=['Date'], parse_dates=['Date'])\n",
    "    stock_ticker.sort_values('Date')\n",
    "    stock_ticker = stock_ticker[start_date: end_date]\n",
    "    #print(stock_ticker.info())\n",
    "\n",
    "    stock_ticker.reset_index(inplace=True)\n",
    "    \n",
    "    data_df = stock_ticker.copy()\n",
    "    data_df = data_df.reset_index()\n",
    "    org_dates = data_df['Date']\n",
    "    data_df['Pretty Date'] = data_df['Date']\n",
    "    \n",
    "\n",
    "    # Converting Dates to Numbers - SVR doesn't work with dates\n",
    "    data_df['Date'] = data_df['Date'].map(mdates.date2num)\n",
    "\n",
    "    indicator_bb = ta.volatility.BollingerBands(close=data_df[close_feature], n=20, ndev=2)\n",
    "    indicator_SMA20 = ta.trend.SMAIndicator(close=data_df[close_feature],n=20, fillna=True)\n",
    "    indicator_MACD = ta.trend.MACD(close=data_df[close_feature],n_fast=5, n_slow=30, fillna=True)\n",
    "  \n",
    "    # Features added to original date\n",
    "    data_df['SMA_20'] = indicator_SMA20.sma_indicator()\n",
    "    data_df['bb_bbm'] = indicator_bb.bollinger_mavg()\n",
    "    data_df['bb_bbh'] = indicator_bb.bollinger_hband()\n",
    "    data_df['bb_bbl'] = indicator_bb.bollinger_lband()\n",
    "    data_df['MACD'] = indicator_MACD.macd()\n",
    "    data_df['MACD signal'] = indicator_MACD.macd_signal()\n",
    "\n",
    "    # Return DF with Dates converted to numerical format and the original Dates for plotting\n",
    "    return data_df, org_dates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data from the Market Data Provider\n",
    "\n",
    "> Note: this uses a local data path setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:NOTEBOOK_LOGGER:files downloaded to ./.data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## setup for file download to local path -- this is used for other\n",
    "local_data_path = './.data'\n",
    "\n",
    "## dates in epoch time\n",
    "start_epoch = get_epoch_date(2008,3,30)\n",
    "end_epoch   = get_epoch_date(2020,3,1)\n",
    "\n",
    "# our symbols as needed by the provider. NOTE ^GSPC becomes _GSPC\n",
    "symbols = ['MSFT', 'AAPL', 'GOOG', '^GSPC', 'AMZN' ]\n",
    "\n",
    "# the actual pull\n",
    "pull_data_files(local_data_path, symbols, start_epoch, end_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature enrichment\n",
    "\n",
    "This step changes dates to serial numbers and adds several features\n",
    "\n",
    "- SMA 20\n",
    "- bollinger band for 20 days:\n",
    "    - Moving Average\n",
    "    - High and Low band\n",
    "- MACD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## setup some data frames for modeling\n",
    "start_date = '2019-01-31'\n",
    "end_date = '2020-03-31'\n",
    "\n",
    "file_target = '{}/{}.csv'\n",
    "\n",
    "MSFT, MSFT_dates = convert_data_add_features(file_target.format(local_data_path, 'MSFT'),start_date, end_date)\n",
    "AAPL, AAPL_dates = convert_data_add_features(file_target.format(local_data_path, 'AAPL'),start_date, end_date)\n",
    "AMZN, AMZN_dates = convert_data_add_features(file_target.format(local_data_path, 'AMZN'),start_date, end_date)\n",
    "GOOG, GOOG_dates = convert_data_add_features(file_target.format(local_data_path, 'GOOG'),start_date, end_date)\n",
    "_GSPC, _GSPC_dates = convert_data_add_features(file_target.format(local_data_path, '_GSPC'),start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Exploratory Analysis\n",
    "\n",
    ">TODO: what kind of diagrams, tables, etc. to put here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Wrangling and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation and Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
